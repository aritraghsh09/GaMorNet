{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "gamornet_basics_tutorial.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aritraghsh09/GaMorNet/blob/master/tutorials/gamornet_train_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNq4HgykhnJK",
        "colab_type": "text"
      },
      "source": [
        "# Google Colab Stuff\n",
        "\n",
        "Although this tutorial can be run on any machine which has GaMorNet installed, it's pretty handy to run this on Google Colab as you can easily use Colab's GPUs for this tutorial.\n",
        "\n",
        "Note that with the free version of Colab, you will only have access to a limited amount of memory available. Thus, the number of images we use here for training/testing very small just for the purpose of demonstration. In reality, GaMorNet can hands hundreds of thousands of images. \n",
        "\n",
        "This first section is meant to be run only when following this tutorial in Google Colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2wSGVu4ihqa",
        "colab_type": "text"
      },
      "source": [
        "### Make things Fast!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWvqtYGaijke",
        "colab_type": "text"
      },
      "source": [
        "Before we dive in, let's make sure we're using a GPU for this tutorial.  \n",
        "\n",
        "To do this, select \"Runtime\" -> \"Change runtime type\" -> \"Hardware accelerator\" -> \"GPU\".\n",
        "\n",
        "The following snippet will verify that we have access to a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbBNuljhhnyf",
        "colab_type": "code",
        "outputId": "47a7b484-cf4e-4658-b1ad-9cde9c3f7fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "# Suppressing TF warnings and info for a cleaner environ\n",
        "# Set this to 0,1 for info and warnings respectively.\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        " \n",
        "# Magic telling Colab we want TF version ~=1.0\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "#Checking access to GPU\n",
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
        "  print('WARNING: GPU device not found.')\n",
        "else:\n",
        "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "SUCCESS: Found GPU: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en4lZVmont-b",
        "colab_type": "text"
      },
      "source": [
        "### Install GaMorNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywr-x3csgQ5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q --upgrade gamornet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYsnfr7tj3D-",
        "colab_type": "code",
        "outputId": "033a0dde-ab38-4753-b217-620286bb2bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "##Checking which version of Tensorflow is being used and whether the installation worked.\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from gamornet.keras_module import gamornet_train_keras, gamornet_tl_keras, gamornet_predict_keras\n",
        "from gamornet.tflearn_module import gamornet_train_tflearn, gamornet_tl_tflearn, gamornet_predict_tflearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isCigPq4TiWi",
        "colab_type": "text"
      },
      "source": [
        "# Reference\n",
        "\n",
        "All mentions of \"the paper\" in this tutorial, refer to [Ghosh et. al. (2020)](https://iopscience.iop.org/article/10.3847/1538-4357/ab8a47)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUDD3Qke7Ws_",
        "colab_type": "text"
      },
      "source": [
        "# Installing Libraries Needed for this Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBSCZfMM7WJV",
        "colab_type": "code",
        "outputId": "d695c26e-2373-4f4c-cee0-c860c8ef2079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!pip install matplotlib\n",
        "!pip install astropy\n",
        "!pip install numpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.6/dist-packages (4.0.1.post1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from astropy) (1.18.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZdvFR_IgTmn",
        "colab_type": "text"
      },
      "source": [
        "# Training with GaMorNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0MNIlNUSZJ8",
        "colab_type": "text"
      },
      "source": [
        "GaMorNet can quite easily be trained from scratch using images. \n",
        "\n",
        "In this demonstration, we will use 90 simulated SDSS images for the purposes of training and 10 simulated SDSS images for validation. All these simulated images come from the set of simulated galaxies created for the paper. \n",
        "\n",
        "All these images contain disk + bulge components. As described in the paper, we have also convolved these simulations with a representative PSF and added representative noise. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwzpM9YMUPqn",
        "colab_type": "text"
      },
      "source": [
        "# Downloading the Data\n",
        "\n",
        "First, let's download the images that we are going to use to train GaMorNet. We will download these into the local filesystem from Yale Astronomy's FTP service, where these are hosted.\n",
        "\n",
        "We are going to download all the 100 images (90+10) as a single archive and then export it to a single folder called `training_imgs`. The iamges are in the FITS format and are named `output_img_xx.fits` where xx runs from 0 to 99.\n",
        "\n",
        "We are also going to download the `sim_para.txt` file containing the ground-truth parameters for the above galaxies. Using these values, we are going to calculate the bulge-to-total light ratio of each galaxy and determine the labels to be used during the training process. \n",
        "\n",
        "\n",
        "*Tip: The `%%bash` command lets Colab know that all the commands in this shell needs to be passed the local unix virtual environment.*\n",
        "\n",
        "*Tip: To view the files in use on Colab, click the folder icon on the left sidebar.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TThUIR8Y4lc",
        "colab_type": "code",
        "outputId": "4db28ed3-9535-449b-9789-15e368b130fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash\n",
        "#get zip and txt file from server\n",
        "wget ftp://ftp.astro.yale.edu/pub/aghosh/gamornet_tutorial_files/train_images/training_imgs.tar.gz\n",
        "wget ftp://ftp.astro.yale.edu/pub/aghosh/gamornet_tutorial_files/train_images/sim_para.txt\n",
        "\n",
        "#Unzip the Archive\n",
        "tar -xvf training_imgs.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./train_images/output_img_0.fits\n",
            "./train_images/output_img_10.fits\n",
            "./train_images/output_img_11.fits\n",
            "./train_images/output_img_12.fits\n",
            "./train_images/output_img_13.fits\n",
            "./train_images/output_img_14.fits\n",
            "./train_images/output_img_15.fits\n",
            "./train_images/output_img_16.fits\n",
            "./train_images/output_img_17.fits\n",
            "./train_images/output_img_18.fits\n",
            "./train_images/output_img_19.fits\n",
            "./train_images/output_img_1.fits\n",
            "./train_images/output_img_20.fits\n",
            "./train_images/output_img_21.fits\n",
            "./train_images/output_img_22.fits\n",
            "./train_images/output_img_23.fits\n",
            "./train_images/output_img_24.fits\n",
            "./train_images/output_img_25.fits\n",
            "./train_images/output_img_26.fits\n",
            "./train_images/output_img_27.fits\n",
            "./train_images/output_img_28.fits\n",
            "./train_images/output_img_29.fits\n",
            "./train_images/output_img_2.fits\n",
            "./train_images/output_img_30.fits\n",
            "./train_images/output_img_31.fits\n",
            "./train_images/output_img_32.fits\n",
            "./train_images/output_img_33.fits\n",
            "./train_images/output_img_34.fits\n",
            "./train_images/output_img_35.fits\n",
            "./train_images/output_img_36.fits\n",
            "./train_images/output_img_37.fits\n",
            "./train_images/output_img_38.fits\n",
            "./train_images/output_img_39.fits\n",
            "./train_images/output_img_3.fits\n",
            "./train_images/output_img_40.fits\n",
            "./train_images/output_img_41.fits\n",
            "./train_images/output_img_42.fits\n",
            "./train_images/output_img_43.fits\n",
            "./train_images/output_img_44.fits\n",
            "./train_images/output_img_45.fits\n",
            "./train_images/output_img_46.fits\n",
            "./train_images/output_img_47.fits\n",
            "./train_images/output_img_48.fits\n",
            "./train_images/output_img_49.fits\n",
            "./train_images/output_img_4.fits\n",
            "./train_images/output_img_50.fits\n",
            "./train_images/output_img_51.fits\n",
            "./train_images/output_img_52.fits\n",
            "./train_images/output_img_53.fits\n",
            "./train_images/output_img_54.fits\n",
            "./train_images/output_img_55.fits\n",
            "./train_images/output_img_56.fits\n",
            "./train_images/output_img_57.fits\n",
            "./train_images/output_img_58.fits\n",
            "./train_images/output_img_59.fits\n",
            "./train_images/output_img_5.fits\n",
            "./train_images/output_img_60.fits\n",
            "./train_images/output_img_61.fits\n",
            "./train_images/output_img_62.fits\n",
            "./train_images/output_img_63.fits\n",
            "./train_images/output_img_64.fits\n",
            "./train_images/output_img_65.fits\n",
            "./train_images/output_img_66.fits\n",
            "./train_images/output_img_67.fits\n",
            "./train_images/output_img_68.fits\n",
            "./train_images/output_img_69.fits\n",
            "./train_images/output_img_6.fits\n",
            "./train_images/output_img_70.fits\n",
            "./train_images/output_img_71.fits\n",
            "./train_images/output_img_72.fits\n",
            "./train_images/output_img_73.fits\n",
            "./train_images/output_img_74.fits\n",
            "./train_images/output_img_75.fits\n",
            "./train_images/output_img_76.fits\n",
            "./train_images/output_img_77.fits\n",
            "./train_images/output_img_78.fits\n",
            "./train_images/output_img_79.fits\n",
            "./train_images/output_img_7.fits\n",
            "./train_images/output_img_80.fits\n",
            "./train_images/output_img_81.fits\n",
            "./train_images/output_img_82.fits\n",
            "./train_images/output_img_83.fits\n",
            "./train_images/output_img_84.fits\n",
            "./train_images/output_img_85.fits\n",
            "./train_images/output_img_86.fits\n",
            "./train_images/output_img_87.fits\n",
            "./train_images/output_img_88.fits\n",
            "./train_images/output_img_89.fits\n",
            "./train_images/output_img_8.fits\n",
            "./train_images/output_img_90.fits\n",
            "./train_images/output_img_91.fits\n",
            "./train_images/output_img_92.fits\n",
            "./train_images/output_img_93.fits\n",
            "./train_images/output_img_94.fits\n",
            "./train_images/output_img_95.fits\n",
            "./train_images/output_img_96.fits\n",
            "./train_images/output_img_97.fits\n",
            "./train_images/output_img_98.fits\n",
            "./train_images/output_img_99.fits\n",
            "./train_images/output_img_9.fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--2020-06-11 06:56:06--  ftp://ftp.astro.yale.edu/pub/aghosh/gamornet_tutorial_files/train_images/training_imgs.tar.gz\n",
            "           => ‘training_imgs.tar.gz.1’\n",
            "Resolving ftp.astro.yale.edu (ftp.astro.yale.edu)... 128.36.139.12\n",
            "Connecting to ftp.astro.yale.edu (ftp.astro.yale.edu)|128.36.139.12|:21... connected.\n",
            "Logging in as anonymous ... Logged in!\n",
            "==> SYST ... done.    ==> PWD ... done.\n",
            "==> TYPE I ... done.  ==> CWD (1) /pub/aghosh/gamornet_tutorial_files/train_images ... done.\n",
            "==> SIZE training_imgs.tar.gz ... 13849775\n",
            "==> PASV ... done.    ==> RETR training_imgs.tar.gz ... done.\n",
            "Length: 13849775 (13M) (unauthoritative)\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0%  224K 60s\n",
            "    50K .......... .......... .......... .......... ..........  0%  520K 43s\n",
            "   100K .......... .......... .......... .......... ..........  1%  489K 38s\n",
            "   150K .......... .......... .......... .......... ..........  1%  120M 28s\n",
            "   200K .......... .......... .......... .......... ..........  1%  164M 22s\n",
            "   250K .......... .......... .......... .......... ..........  2%  508K 23s\n",
            "   300K .......... .......... .......... .......... ..........  2%  257M 20s\n",
            "   350K .......... .......... .......... .......... ..........  2%  163M 17s\n",
            "   400K .......... .......... .......... .......... ..........  3%  186M 15s\n",
            "   450K .......... .......... .......... .......... ..........  3%  210M 14s\n",
            "   500K .......... .......... .......... .......... ..........  4%  566K 14s\n",
            "   550K .......... .......... .......... .......... ..........  4% 86.4M 13s\n",
            "   600K .......... .......... .......... .......... ..........  4%  104M 12s\n",
            "   650K .......... .......... .......... .......... ..........  5% 78.9M 11s\n",
            "   700K .......... .......... .......... .......... ..........  5% 86.0M 10s\n",
            "   750K .......... .......... .......... .......... ..........  5%  112M 10s\n",
            "   800K .......... .......... .......... .......... ..........  6%  110M 9s\n",
            "   850K .......... .......... .......... .......... ..........  6%  110M 9s\n",
            "   900K .......... .......... .......... .......... ..........  7%  114M 8s\n",
            "   950K .......... .......... .......... .......... ..........  7%  112M 8s\n",
            "  1000K .......... .......... .......... .......... ..........  7%  105M 7s\n",
            "  1050K .......... .......... .......... .......... ..........  8%  588K 8s\n",
            "  1100K .......... .......... .......... .......... ..........  8%  117M 8s\n",
            "  1150K .......... .......... .......... .......... ..........  8%  126M 7s\n",
            "  1200K .......... .......... .......... .......... ..........  9% 94.4M 7s\n",
            "  1250K .......... .......... .......... .......... ..........  9%  114M 7s\n",
            "  1300K .......... .......... .......... .......... ..........  9%  115M 6s\n",
            "  1350K .......... .......... .......... .......... .......... 10%  122M 6s\n",
            "  1400K .......... .......... .......... .......... .......... 10%  111M 6s\n",
            "  1450K .......... .......... .......... .......... .......... 11%  108M 6s\n",
            "  1500K .......... .......... .......... .......... .......... 11%  112M 5s\n",
            "  1550K .......... .......... .......... .......... .......... 11%  131M 5s\n",
            "  1600K .......... .......... .......... .......... .......... 12% 98.5M 5s\n",
            "  1650K .......... .......... .......... .......... .......... 12%  119M 5s\n",
            "  1700K .......... .......... .......... .......... .......... 12%  112M 5s\n",
            "  1750K .......... .......... .......... .......... .......... 13%  115M 5s\n",
            "  1800K .......... .......... .......... .......... .......... 13%  111M 4s\n",
            "  1850K .......... .......... .......... .......... .......... 14%  104M 4s\n",
            "  1900K .......... .......... .......... .......... .......... 14%  118M 4s\n",
            "  1950K .......... .......... .......... .......... .......... 14%  111M 4s\n",
            "  2000K .......... .......... .......... .......... .......... 15%  107M 4s\n",
            "  2050K .......... .......... .......... .......... .......... 15%  123M 4s\n",
            "  2100K .......... .......... .......... .......... .......... 15%  616K 4s\n",
            "  2150K .......... .......... .......... .......... .......... 16%  146M 4s\n",
            "  2200K .......... .......... .......... .......... .......... 16%  115M 4s\n",
            "  2250K .......... .......... .......... .......... .......... 17%  107M 4s\n",
            "  2300K .......... .......... .......... .......... .......... 17%  119M 4s\n",
            "  2350K .......... .......... .......... .......... .......... 17%  117M 4s\n",
            "  2400K .......... .......... .......... .......... .......... 18%  112M 4s\n",
            "  2450K .......... .......... .......... .......... .......... 18%  125M 3s\n",
            "  2500K .......... .......... .......... .......... .......... 18% 96.7M 3s\n",
            "  2550K .......... .......... .......... .......... .......... 19%  116M 3s\n",
            "  2600K .......... .......... .......... .......... .......... 19%  115M 3s\n",
            "  2650K .......... .......... .......... .......... .......... 19%  104M 3s\n",
            "  2700K .......... .......... .......... .......... .......... 20%  133M 3s\n",
            "  2750K .......... .......... .......... .......... .......... 20%  107M 3s\n",
            "  2800K .......... .......... .......... .......... .......... 21% 93.9M 3s\n",
            "  2850K .......... .......... .......... .......... .......... 21%  137M 3s\n",
            "  2900K .......... .......... .......... .......... .......... 21%  115M 3s\n",
            "  2950K .......... .......... .......... .......... .......... 22%  111M 3s\n",
            "  3000K .......... .......... .......... .......... .......... 22%  108M 3s\n",
            "  3050K .......... .......... .......... .......... .......... 22%  114M 3s\n",
            "  3100K .......... .......... .......... .......... .......... 23%  112M 3s\n",
            "  3150K .......... .......... .......... .......... .......... 23%  110M 3s\n",
            "  3200K .......... .......... .......... .......... .......... 24%  116M 3s\n",
            "  3250K .......... .......... .......... .......... .......... 24%  114M 2s\n",
            "  3300K .......... .......... .......... .......... .......... 24%  111M 2s\n",
            "  3350K .......... .......... .......... .......... .......... 25%  118M 2s\n",
            "  3400K .......... .......... .......... .......... .......... 25% 77.1M 2s\n",
            "  3450K .......... .......... .......... .......... .......... 25%  149M 2s\n",
            "  3500K .......... .......... .......... .......... .......... 26%  115M 2s\n",
            "  3550K .......... .......... .......... .......... .......... 26% 98.2M 2s\n",
            "  3600K .......... .......... .......... .......... .......... 26%  144M 2s\n",
            "  3650K .......... .......... .......... .......... .......... 27%  107M 2s\n",
            "  3700K .......... .......... .......... .......... .......... 27% 95.7M 2s\n",
            "  3750K .......... .......... .......... .......... .......... 28%  133M 2s\n",
            "  3800K .......... .......... .......... .......... .......... 28%  112M 2s\n",
            "  3850K .......... .......... .......... .......... .......... 28%  111M 2s\n",
            "  3900K .......... .......... .......... .......... .......... 29%  134M 2s\n",
            "  3950K .......... .......... .......... .......... .......... 29%  107M 2s\n",
            "  4000K .......... .......... .......... .......... .......... 29%  107M 2s\n",
            "  4050K .......... .......... .......... .......... .......... 30%  121M 2s\n",
            "  4100K .......... .......... .......... .......... .......... 30%  108M 2s\n",
            "  4150K .......... .......... .......... .......... .......... 31%  693K 2s\n",
            "  4200K .......... .......... .......... .......... .......... 31%  150M 2s\n",
            "  4250K .......... .......... .......... .......... .......... 31% 95.6M 2s\n",
            "  4300K .......... .......... .......... .......... .......... 32%  135M 2s\n",
            "  4350K .......... .......... .......... .......... .......... 32%  133M 2s\n",
            "  4400K .......... .......... .......... .......... .......... 32% 98.7M 2s\n",
            "  4450K .......... .......... .......... .......... .......... 33%  121M 2s\n",
            "  4500K .......... .......... .......... .......... .......... 33%  114M 2s\n",
            "  4550K .......... .......... .......... .......... .......... 34% 97.4M 2s\n",
            "  4600K .......... .......... .......... .......... .......... 34%  135M 2s\n",
            "  4650K .......... .......... .......... .......... .......... 34%  103M 2s\n",
            "  4700K .......... .......... .......... .......... .......... 35%  110M 2s\n",
            "  4750K .......... .......... .......... .......... .......... 35%  121M 2s\n",
            "  4800K .......... .......... .......... .......... .......... 35%  122M 2s\n",
            "  4850K .......... .......... .......... .......... .......... 36%  100M 2s\n",
            "  4900K .......... .......... .......... .......... .......... 36%  118M 2s\n",
            "  4950K .......... .......... .......... .......... .......... 36%  118M 2s\n",
            "  5000K .......... .......... .......... .......... .......... 37%  122M 1s\n",
            "  5050K .......... .......... .......... .......... .......... 37% 95.1M 1s\n",
            "  5100K .......... .......... .......... .......... .......... 38%  107M 1s\n",
            "  5150K .......... .......... .......... .......... .......... 38%  133M 1s\n",
            "  5200K .......... .......... .......... .......... .......... 38% 89.2M 1s\n",
            "  5250K .......... .......... .......... .......... .......... 39%  142M 1s\n",
            "  5300K .......... .......... .......... .......... .......... 39%  116M 1s\n",
            "  5350K .......... .......... .......... .......... .......... 39%  100M 1s\n",
            "  5400K .......... .......... .......... .......... .......... 40%  111M 1s\n",
            "  5450K .......... .......... .......... .......... .......... 40%  124M 1s\n",
            "  5500K .......... .......... .......... .......... .......... 41%  118M 1s\n",
            "  5550K .......... .......... .......... .......... .......... 41%  101M 1s\n",
            "  5600K .......... .......... .......... .......... .......... 41%  115M 1s\n",
            "  5650K .......... .......... .......... .......... .......... 42%  120M 1s\n",
            "  5700K .......... .......... .......... .......... .......... 42%  110M 1s\n",
            "  5750K .......... .......... .......... .......... .......... 42%  118M 1s\n",
            "  5800K .......... .......... .......... .......... .......... 43%  116M 1s\n",
            "  5850K .......... .......... .......... .......... .......... 43%  108M 1s\n",
            "  5900K .......... .......... .......... .......... .......... 43%  106M 1s\n",
            "  5950K .......... .......... .......... .......... .......... 44%  120M 1s\n",
            "  6000K .......... .......... .......... .......... .......... 44%  116M 1s\n",
            "  6050K .......... .......... .......... .......... .......... 45%  109M 1s\n",
            "  6100K .......... .......... .......... .......... .......... 45% 88.3M 1s\n",
            "  6150K .......... .......... .......... .......... .......... 45%  129M 1s\n",
            "  6200K .......... .......... .......... .......... .......... 46%  107M 1s\n",
            "  6250K .......... .......... .......... .......... .......... 46%  115M 1s\n",
            "  6300K .......... .......... .......... .......... .......... 46%  144M 1s\n",
            "  6350K .......... .......... .......... .......... .......... 47%  111M 1s\n",
            "  6400K .......... .......... .......... .......... .......... 47%  109M 1s\n",
            "  6450K .......... .......... .......... .......... .......... 48%  102M 1s\n",
            "  6500K .......... .......... .......... .......... .......... 48%  127M 1s\n",
            "  6550K .......... .......... .......... .......... .......... 48% 98.1M 1s\n",
            "  6600K .......... .......... .......... .......... .......... 49%  118M 1s\n",
            "  6650K .......... .......... .......... .......... .......... 49%  113M 1s\n",
            "  6700K .......... .......... .......... .......... .......... 49%  111M 1s\n",
            "  6750K .......... .......... .......... .......... .......... 50%  108M 1s\n",
            "  6800K .......... .......... .......... .......... .......... 50%  103M 1s\n",
            "  6850K .......... .......... .......... .......... .......... 51%  120M 1s\n",
            "  6900K .......... .......... .......... .......... .......... 51%  135M 1s\n",
            "  6950K .......... .......... .......... .......... .......... 51% 99.9M 1s\n",
            "  7000K .......... .......... .......... .......... .......... 52%  124M 1s\n",
            "  7050K .......... .......... .......... .......... .......... 52%  111M 1s\n",
            "  7100K .......... .......... .......... .......... .......... 52%  114M 1s\n",
            "  7150K .......... .......... .......... .......... .......... 53%  103M 1s\n",
            "  7200K .......... .......... .......... .......... .......... 53%  787K 1s\n",
            "  7250K .......... .......... .......... .......... .......... 53% 68.2M 1s\n",
            "  7300K .......... .......... .......... .......... .......... 54%  107M 1s\n",
            "  7350K .......... .......... .......... .......... .......... 54% 78.5M 1s\n",
            "  7400K .......... .......... .......... .......... .......... 55%  105M 1s\n",
            "  7450K .......... .......... .......... .......... .......... 55%  102M 1s\n",
            "  7500K .......... .......... .......... .......... .......... 55% 97.8M 1s\n",
            "  7550K .......... .......... .......... .......... .......... 56% 96.3M 1s\n",
            "  7600K .......... .......... .......... .......... .......... 56%  109M 1s\n",
            "  7650K .......... .......... .......... .......... .......... 56% 94.1M 1s\n",
            "  7700K .......... .......... .......... .......... .......... 57% 93.6M 1s\n",
            "  7750K .......... .......... .......... .......... .......... 57% 81.3M 1s\n",
            "  7800K .......... .......... .......... .......... .......... 58%  121M 1s\n",
            "  7850K .......... .......... .......... .......... .......... 58%  106M 1s\n",
            "  7900K .......... .......... .......... .......... .......... 58%  192M 1s\n",
            "  7950K .......... .......... .......... .......... .......... 59% 18.0M 1s\n",
            "  8000K .......... .......... .......... .......... .......... 59% 93.0M 1s\n",
            "  8050K .......... .......... .......... .......... .......... 59% 88.4M 1s\n",
            "  8100K .......... .......... .......... .......... .......... 60%  195M 1s\n",
            "  8150K .......... .......... .......... .......... .......... 60%  120M 1s\n",
            "  8200K .......... .......... .......... .......... .......... 60%  100M 1s\n",
            "  8250K .......... .......... .......... .......... .......... 61%  129M 1s\n",
            "  8300K .......... .......... .......... .......... .......... 61%  117M 1s\n",
            "  8350K .......... .......... .......... .......... .......... 62%  111M 1s\n",
            "  8400K .......... .......... .......... .......... .......... 62%  101M 1s\n",
            "  8450K .......... .......... .......... .......... .......... 62%  107M 1s\n",
            "  8500K .......... .......... .......... .......... .......... 63%  123M 1s\n",
            "  8550K .......... .......... .......... .......... .......... 63%  119M 1s\n",
            "  8600K .......... .......... .......... .......... .......... 63%  107M 1s\n",
            "  8650K .......... .......... .......... .......... .......... 64% 89.1M 1s\n",
            "  8700K .......... .......... .......... .......... .......... 64%  124M 1s\n",
            "  8750K .......... .......... .......... .......... .......... 65%  145M 1s\n",
            "  8800K .......... .......... .......... .......... .......... 65%  104M 1s\n",
            "  8850K .......... .......... .......... .......... .......... 65% 93.4M 1s\n",
            "  8900K .......... .......... .......... .......... .......... 66%  140M 1s\n",
            "  8950K .......... .......... .......... .......... .......... 66%  122M 0s\n",
            "  9000K .......... .......... .......... .......... .......... 66%  115M 0s\n",
            "  9050K .......... .......... .......... .......... .......... 67%  104M 0s\n",
            "  9100K .......... .......... .......... .......... .......... 67%  104M 0s\n",
            "  9150K .......... .......... .......... .......... .......... 68%  125M 0s\n",
            "  9200K .......... .......... .......... .......... .......... 68%  104M 0s\n",
            "  9250K .......... .......... .......... .......... .......... 68%  130M 0s\n",
            "  9300K .......... .......... .......... .......... .......... 69%  102M 0s\n",
            "  9350K .......... .......... .......... .......... .......... 69%  107M 0s\n",
            "  9400K .......... .......... .......... .......... .......... 69%  104M 0s\n",
            "  9450K .......... .......... .......... .......... .......... 70%  113M 0s\n",
            "  9500K .......... .......... .......... .......... .......... 70%  117M 0s\n",
            "  9550K .......... .......... .......... .......... .......... 70%  107M 0s\n",
            "  9600K .......... .......... .......... .......... .......... 71%  113M 0s\n",
            "  9650K .......... .......... .......... .......... .......... 71%  106M 0s\n",
            "  9700K .......... .......... .......... .......... .......... 72%  105M 0s\n",
            "  9750K .......... .......... .......... .......... .......... 72%  112M 0s\n",
            "  9800K .......... .......... .......... .......... .......... 72%  132M 0s\n",
            "  9850K .......... .......... .......... .......... .......... 73%  116M 0s\n",
            "  9900K .......... .......... .......... .......... .......... 73%  106M 0s\n",
            "  9950K .......... .......... .......... .......... .......... 73%  103M 0s\n",
            " 10000K .......... .......... .......... .......... .......... 74%  135M 0s\n",
            " 10050K .......... .......... .......... .......... .......... 74% 83.1M 0s\n",
            " 10100K .......... .......... .......... .......... .......... 75%  122M 0s\n",
            " 10150K .......... .......... .......... .......... .......... 75%  136M 0s\n",
            " 10200K .......... .......... .......... .......... .......... 75%  124M 0s\n",
            " 10250K .......... .......... .......... .......... .......... 76%  113M 0s\n",
            " 10300K .......... .......... .......... .......... .......... 76%  822K 0s\n",
            " 10350K .......... .......... .......... .......... .......... 76% 92.3M 0s\n",
            " 10400K .......... .......... .......... .......... .......... 77% 69.4M 0s\n",
            " 10450K .......... .......... .......... .......... .......... 77% 95.5M 0s\n",
            " 10500K .......... .......... .......... .......... .......... 78%  122M 0s\n",
            " 10550K .......... .......... .......... .......... .......... 78% 95.6M 0s\n",
            " 10600K .......... .......... .......... .......... .......... 78%  109M 0s\n",
            " 10650K .......... .......... .......... .......... .......... 79%  111M 0s\n",
            " 10700K .......... .......... .......... .......... .......... 79% 87.7M 0s\n",
            " 10750K .......... .......... .......... .......... .......... 79%  110M 0s\n",
            " 10800K .......... .......... .......... .......... .......... 80% 8.60M 0s\n",
            " 10850K .......... .......... .......... .......... .......... 80%  103M 0s\n",
            " 10900K .......... .......... .......... .......... .......... 80%  117M 0s\n",
            " 10950K .......... .......... .......... .......... .......... 81%  136M 0s\n",
            " 11000K .......... .......... .......... .......... .......... 81%  107M 0s\n",
            " 11050K .......... .......... .......... .......... .......... 82%  123M 0s\n",
            " 11100K .......... .......... .......... .......... .......... 82%  103M 0s\n",
            " 11150K .......... .......... .......... .......... .......... 82%  120M 0s\n",
            " 11200K .......... .......... .......... .......... .......... 83%  110M 0s\n",
            " 11250K .......... .......... .......... .......... .......... 83%  126M 0s\n",
            " 11300K .......... .......... .......... .......... .......... 83%  103M 0s\n",
            " 11350K .......... .......... .......... .......... .......... 84%  115M 0s\n",
            " 11400K .......... .......... .......... .......... .......... 84%  117M 0s\n",
            " 11450K .......... .......... .......... .......... .......... 85%  113M 0s\n",
            " 11500K .......... .......... .......... .......... .......... 85%  105M 0s\n",
            " 11550K .......... .......... .......... .......... .......... 85%  118M 0s\n",
            " 11600K .......... .......... .......... .......... .......... 86% 99.8M 0s\n",
            " 11650K .......... .......... .......... .......... .......... 86%  129M 0s\n",
            " 11700K .......... .......... .......... .......... .......... 86%  107M 0s\n",
            " 11750K .......... .......... .......... .......... .......... 87%  102M 0s\n",
            " 11800K .......... .......... .......... .......... .......... 87%  133M 0s\n",
            " 11850K .......... .......... .......... .......... .......... 87% 96.9M 0s\n",
            " 11900K .......... .......... .......... .......... .......... 88%  108M 0s\n",
            " 11950K .......... .......... .......... .......... .......... 88%  137M 0s\n",
            " 12000K .......... .......... .......... .......... .......... 89%  110M 0s\n",
            " 12050K .......... .......... .......... .......... .......... 89%  107M 0s\n",
            " 12100K .......... .......... .......... .......... .......... 89%  114M 0s\n",
            " 12150K .......... .......... .......... .......... .......... 90%  108M 0s\n",
            " 12200K .......... .......... .......... .......... .......... 90% 93.9M 0s\n",
            " 12250K .......... .......... .......... .......... .......... 90%  103M 0s\n",
            " 12300K .......... .......... .......... .......... .......... 91%  151M 0s\n",
            " 12350K .......... .......... .......... .......... .......... 91%  103M 0s\n",
            " 12400K .......... .......... .......... .......... .......... 92%  114M 0s\n",
            " 12450K .......... .......... .......... .......... .......... 92%  112M 0s\n",
            " 12500K .......... .......... .......... .......... .......... 92%  110M 0s\n",
            " 12550K .......... .......... .......... .......... .......... 93% 97.6M 0s\n",
            " 12600K .......... .......... .......... .......... .......... 93%  121M 0s\n",
            " 12650K .......... .......... .......... .......... .......... 93%  120M 0s\n",
            " 12700K .......... .......... .......... .......... .......... 94%  113M 0s\n",
            " 12750K .......... .......... .......... .......... .......... 94%  102M 0s\n",
            " 12800K .......... .......... .......... .......... .......... 95%  114M 0s\n",
            " 12850K .......... .......... .......... .......... .......... 95%  112M 0s\n",
            " 12900K .......... .......... .......... .......... .......... 95%  113M 0s\n",
            " 12950K .......... .......... .......... .......... .......... 96%  115M 0s\n",
            " 13000K .......... .......... .......... .......... .......... 96%  111M 0s\n",
            " 13050K .......... .......... .......... .......... .......... 96%  116M 0s\n",
            " 13100K .......... .......... .......... .......... .......... 97%  108M 0s\n",
            " 13150K .......... .......... .......... .......... .......... 97%  127M 0s\n",
            " 13200K .......... .......... .......... .......... .......... 97%  107M 0s\n",
            " 13250K .......... .......... .......... .......... .......... 98%  111M 0s\n",
            " 13300K .......... .......... .......... .......... .......... 98%  107M 0s\n",
            " 13350K .......... .......... .......... .......... .......... 99%  865K 0s\n",
            " 13400K .......... .......... .......... .......... .......... 99% 89.4M 0s\n",
            " 13450K .......... .......... .......... .......... .......... 99% 85.4M 0s\n",
            " 13500K .......... .......... .....                           100% 95.7M=1.2s\n",
            "\n",
            "2020-06-11 06:56:08 (11.5 MB/s) - ‘training_imgs.tar.gz.1’ saved [13849775]\n",
            "\n",
            "--2020-06-11 06:56:08--  ftp://ftp.astro.yale.edu/pub/aghosh/gamornet_tutorial_files/train_images/sim_para.txt\n",
            "           => ‘sim_para.txt.1’\n",
            "Resolving ftp.astro.yale.edu (ftp.astro.yale.edu)... 128.36.139.12\n",
            "Connecting to ftp.astro.yale.edu (ftp.astro.yale.edu)|128.36.139.12|:21... connected.\n",
            "Logging in as anonymous ... Logged in!\n",
            "==> SYST ... done.    ==> PWD ... done.\n",
            "==> TYPE I ... done.  ==> CWD (1) /pub/aghosh/gamornet_tutorial_files/train_images ... done.\n",
            "==> SIZE sim_para.txt ... 11676\n",
            "==> PASV ... done.    ==> RETR sim_para.txt ... done.\n",
            "Length: 11676 (11K) (unauthoritative)\n",
            "\n",
            "     0K .......... .                                          100% 13.8M=0.001s\n",
            "\n",
            "2020-06-11 06:56:10 (13.8 MB/s) - ‘sim_para.txt.1’ saved [11676]\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAwLO4hk-C3Q",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the Data\n",
        "\n",
        "In this section, we will generate the training and validation image arrays as well as the corresponding labels to be used during the training process.\n",
        "\n",
        "\n",
        "First, lets read in the `.txt` file and calculate the difference in disk and bulge magnitudes for each of the galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex46Lm2c_3I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pylab as plt\n",
        "\n",
        "#Let's read in the sim_para.txt file \n",
        "gal_para = plt.genfromtxt(\"./sim_para.txt\",names=True,usecols = (4,11))\n",
        " \n",
        "#difference b/w the integrated magnitude of the disk and bulge components. \n",
        "#The rows in the file and thus the elements in the array below correspond to\n",
        "#the numbers in the names of the image files. (i.e. the 0th element corresponds\n",
        "#to output_img_0.fits)\n",
        "disk_bulge_mag = gal_para[\"Inte_Mag\"] - gal_para[\"Inte_Mag_2\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pDautJ1CWTy",
        "colab_type": "text"
      },
      "source": [
        "Next, let's define two convenience functions, which will assist us in creating the image and label arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWcg5PBi-RSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convenience Function to get and return images as numpy arrays\n",
        "\n",
        "def image_handler(i):\n",
        "  return np.reshape(fits.getdata(\"./train_images/output_img_\"+str(i)+\".fits\",\n",
        "                                 memmap=False),newshape=(167,167,1)) \n",
        "  #We use the reshape command just to add the extra 3rd dimension. The image is \n",
        "  #originally 167*167. So, in essence no re-sizing is taking place in the X or Y\n",
        "  #directions.\n",
        "\n",
        "\n",
        "# Convenience Function to get and return the training labels of each galaxy\n",
        "# in the one-hot encoding format. i.e. disk-dominated galaxies will be represented\n",
        "# by the array [1,0,0], bulge-dominated by [0,0,1] and indeterminate by [0,1,0]\n",
        "\n",
        "def label_handler(i):\n",
        "  \n",
        "  target_vect = [0]*3\n",
        "\n",
        "  if (disk_bulge_mag[i] < -0.22): #  (Lb/LT) < 0.45\n",
        "    target_vect[0] = 1  #disk-dominated       \n",
        "  \n",
        "  elif ( -0.22 <=  disk_bulge_mag[i] <= 0.22):\n",
        "      target_vect[1] = 1 #indeterminate\n",
        "  \n",
        "  else: #  (Lb/LT) > 0.55\n",
        "      target_vect[2] = 1 #bulge-dominated\n",
        "\n",
        "  return target_vect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQesQrpK-Pz2",
        "colab_type": "text"
      },
      "source": [
        "Now, we are going to use the first 90 images to create the training set and the last 10 to create the validation set. We are multi-threading the process below -- although this is an absolute overkill for 100 images, it's very handy while dealing with large numbers of images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_SCF8wWDiSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from multiprocessing import Pool\n",
        "import numpy as np\n",
        "from astropy.io import fits\n",
        "\n",
        "NUM_THREADS = 2\n",
        "\n",
        "pl = Pool(NUM_THREADS)\n",
        "training_imgs = np.array(pl.map(image_handler,range(0,90)))\n",
        "training_labels = np.array(pl.map(label_handler,range(0,90)))\n",
        "\n",
        "valdiation_imgs = np.array(pl.map(image_handler,range(90,100)))\n",
        "validation_labels = np.array(pl.map(label_handler,range(90,100)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw-l4YKMbLdK",
        "colab_type": "text"
      },
      "source": [
        "# Training GaMorNet using Keras\n",
        "\n",
        "Now, we will be using the images and the labels generated above to train GaMorNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBTLm74QbMnG",
        "colab_type": "code",
        "outputId": "1a545fd0-d3c4-41ff-c7c0-7622b39fe42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from gamornet.keras_module import gamornet_train_keras\n",
        "\n",
        "model = gamornet_train_keras(training_imgs,training_labels,valdiation_imgs,\n",
        "                             validation_labels,input_shape='SDSS', epochs=50, \n",
        "                             checkpoint_freq=25, batch_size=64, lr=0.0001, \n",
        "                             loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Train on 90 samples, validate on 10 samples\n",
            "Epoch 1/100\n",
            "90/90 [==============================] - 3s 34ms/step - loss: 2.3470 - accuracy: 0.2889 - val_loss: 0.9786 - val_accuracy: 0.2000\n",
            "Epoch 2/100\n",
            "90/90 [==============================] - 0s 951us/step - loss: 2.1113 - accuracy: 0.3667 - val_loss: 0.4128 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "90/90 [==============================] - 0s 905us/step - loss: 2.2732 - accuracy: 0.4222 - val_loss: 0.2424 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "90/90 [==============================] - 0s 834us/step - loss: 1.9030 - accuracy: 0.4889 - val_loss: 0.2028 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "90/90 [==============================] - 0s 858us/step - loss: 1.8483 - accuracy: 0.5556 - val_loss: 0.1154 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "90/90 [==============================] - 0s 910us/step - loss: 1.2512 - accuracy: 0.6222 - val_loss: 0.0895 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "90/90 [==============================] - 0s 857us/step - loss: 1.3692 - accuracy: 0.6222 - val_loss: 0.0674 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "90/90 [==============================] - 0s 883us/step - loss: 1.5111 - accuracy: 0.6111 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "90/90 [==============================] - 0s 879us/step - loss: 1.6902 - accuracy: 0.5778 - val_loss: 0.0824 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "90/90 [==============================] - 0s 867us/step - loss: 1.3695 - accuracy: 0.5778 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "90/90 [==============================] - 0s 892us/step - loss: 1.4662 - accuracy: 0.5333 - val_loss: 0.0840 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "90/90 [==============================] - 0s 866us/step - loss: 1.6910 - accuracy: 0.5333 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "90/90 [==============================] - 0s 861us/step - loss: 1.1328 - accuracy: 0.5778 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "90/90 [==============================] - 0s 890us/step - loss: 1.1386 - accuracy: 0.5444 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "90/90 [==============================] - 0s 880us/step - loss: 1.5797 - accuracy: 0.6222 - val_loss: 0.0552 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "90/90 [==============================] - 0s 860us/step - loss: 0.9577 - accuracy: 0.6889 - val_loss: 0.0574 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "90/90 [==============================] - 0s 887us/step - loss: 1.0401 - accuracy: 0.6667 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "90/90 [==============================] - 0s 839us/step - loss: 1.2387 - accuracy: 0.6111 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "90/90 [==============================] - 0s 837us/step - loss: 1.0838 - accuracy: 0.6333 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "90/90 [==============================] - 0s 857us/step - loss: 1.2934 - accuracy: 0.7000 - val_loss: 0.0798 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "90/90 [==============================] - 0s 858us/step - loss: 1.1036 - accuracy: 0.6333 - val_loss: 0.1018 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "90/90 [==============================] - 0s 890us/step - loss: 0.6567 - accuracy: 0.7000 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "90/90 [==============================] - 0s 894us/step - loss: 0.7238 - accuracy: 0.7333 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "90/90 [==============================] - 0s 1ms/step - loss: 0.8391 - accuracy: 0.7556 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "90/90 [==============================] - 0s 865us/step - loss: 1.0376 - accuracy: 0.6222 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00025: saving model to ./model_25.hdf5\n",
            "Epoch 26/100\n",
            "90/90 [==============================] - 0s 903us/step - loss: 0.9905 - accuracy: 0.6778 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "90/90 [==============================] - 0s 924us/step - loss: 0.8760 - accuracy: 0.7333 - val_loss: 0.1136 - val_accuracy: 0.9000\n",
            "Epoch 28/100\n",
            "90/90 [==============================] - 0s 891us/step - loss: 1.0688 - accuracy: 0.6889 - val_loss: 0.1003 - val_accuracy: 0.9000\n",
            "Epoch 29/100\n",
            "90/90 [==============================] - 0s 867us/step - loss: 1.0475 - accuracy: 0.7000 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "90/90 [==============================] - 0s 854us/step - loss: 0.9911 - accuracy: 0.7444 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "90/90 [==============================] - 0s 868us/step - loss: 0.6839 - accuracy: 0.7667 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "90/90 [==============================] - 0s 902us/step - loss: 0.7568 - accuracy: 0.7444 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "90/90 [==============================] - 0s 878us/step - loss: 0.7664 - accuracy: 0.7778 - val_loss: 0.1092 - val_accuracy: 0.9000\n",
            "Epoch 34/100\n",
            "90/90 [==============================] - 0s 859us/step - loss: 0.6596 - accuracy: 0.7556 - val_loss: 0.2174 - val_accuracy: 0.9000\n",
            "Epoch 35/100\n",
            "90/90 [==============================] - 0s 869us/step - loss: 0.7918 - accuracy: 0.7222 - val_loss: 0.2364 - val_accuracy: 0.9000\n",
            "Epoch 36/100\n",
            "90/90 [==============================] - 0s 860us/step - loss: 0.8217 - accuracy: 0.7556 - val_loss: 0.1303 - val_accuracy: 0.9000\n",
            "Epoch 37/100\n",
            "90/90 [==============================] - 0s 858us/step - loss: 0.6944 - accuracy: 0.7556 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "90/90 [==============================] - 0s 922us/step - loss: 0.5462 - accuracy: 0.7667 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "90/90 [==============================] - 0s 928us/step - loss: 0.7819 - accuracy: 0.7333 - val_loss: 0.1309 - val_accuracy: 0.9000\n",
            "Epoch 40/100\n",
            "90/90 [==============================] - 0s 897us/step - loss: 0.9322 - accuracy: 0.7556 - val_loss: 0.0883 - val_accuracy: 0.9000\n",
            "Epoch 41/100\n",
            "90/90 [==============================] - 0s 895us/step - loss: 0.7069 - accuracy: 0.7444 - val_loss: 0.0540 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "90/90 [==============================] - 0s 865us/step - loss: 0.7705 - accuracy: 0.7556 - val_loss: 0.1563 - val_accuracy: 0.9000\n",
            "Epoch 43/100\n",
            "90/90 [==============================] - 0s 873us/step - loss: 0.5828 - accuracy: 0.8000 - val_loss: 0.2662 - val_accuracy: 0.9000\n",
            "Epoch 44/100\n",
            "90/90 [==============================] - 0s 846us/step - loss: 0.7962 - accuracy: 0.7556 - val_loss: 0.2287 - val_accuracy: 0.9000\n",
            "Epoch 45/100\n",
            "90/90 [==============================] - 0s 890us/step - loss: 0.7768 - accuracy: 0.7778 - val_loss: 0.1358 - val_accuracy: 0.9000\n",
            "Epoch 46/100\n",
            "90/90 [==============================] - 0s 844us/step - loss: 0.4745 - accuracy: 0.8222 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "90/90 [==============================] - 0s 858us/step - loss: 0.5657 - accuracy: 0.7889 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "90/90 [==============================] - 0s 870us/step - loss: 0.6585 - accuracy: 0.7778 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "90/90 [==============================] - 0s 872us/step - loss: 0.8440 - accuracy: 0.7778 - val_loss: 0.0542 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "90/90 [==============================] - 0s 844us/step - loss: 0.6683 - accuracy: 0.7444 - val_loss: 0.1835 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00050: saving model to ./model_50.hdf5\n",
            "Epoch 51/100\n",
            "90/90 [==============================] - 0s 942us/step - loss: 0.4547 - accuracy: 0.8000 - val_loss: 0.2883 - val_accuracy: 0.9000\n",
            "Epoch 52/100\n",
            "90/90 [==============================] - 0s 886us/step - loss: 0.7825 - accuracy: 0.7556 - val_loss: 0.3228 - val_accuracy: 0.9000\n",
            "Epoch 53/100\n",
            "90/90 [==============================] - 0s 907us/step - loss: 1.0094 - accuracy: 0.7333 - val_loss: 0.2045 - val_accuracy: 0.9000\n",
            "Epoch 54/100\n",
            "90/90 [==============================] - 0s 916us/step - loss: 0.4762 - accuracy: 0.8556 - val_loss: 0.0825 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "90/90 [==============================] - 0s 931us/step - loss: 0.6054 - accuracy: 0.7556 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "90/90 [==============================] - 0s 913us/step - loss: 0.6602 - accuracy: 0.8444 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "90/90 [==============================] - 0s 846us/step - loss: 0.8435 - accuracy: 0.7556 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "90/90 [==============================] - 0s 847us/step - loss: 0.8266 - accuracy: 0.7111 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "90/90 [==============================] - 0s 842us/step - loss: 0.6664 - accuracy: 0.7889 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "90/90 [==============================] - 0s 843us/step - loss: 0.5991 - accuracy: 0.8333 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "90/90 [==============================] - 0s 873us/step - loss: 0.7160 - accuracy: 0.7778 - val_loss: 0.1136 - val_accuracy: 0.9000\n",
            "Epoch 62/100\n",
            "90/90 [==============================] - 0s 878us/step - loss: 0.5808 - accuracy: 0.8333 - val_loss: 0.1266 - val_accuracy: 0.9000\n",
            "Epoch 63/100\n",
            "90/90 [==============================] - 0s 892us/step - loss: 0.6755 - accuracy: 0.7889 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "90/90 [==============================] - 0s 858us/step - loss: 0.4963 - accuracy: 0.7778 - val_loss: 0.1115 - val_accuracy: 0.9000\n",
            "Epoch 65/100\n",
            "90/90 [==============================] - 0s 858us/step - loss: 0.6669 - accuracy: 0.7667 - val_loss: 0.1398 - val_accuracy: 0.9000\n",
            "Epoch 66/100\n",
            "90/90 [==============================] - 0s 848us/step - loss: 0.7479 - accuracy: 0.8000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "90/90 [==============================] - 0s 860us/step - loss: 0.5271 - accuracy: 0.7667 - val_loss: 0.0894 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "90/90 [==============================] - 0s 881us/step - loss: 0.4639 - accuracy: 0.8333 - val_loss: 0.1332 - val_accuracy: 0.9000\n",
            "Epoch 69/100\n",
            "90/90 [==============================] - 0s 859us/step - loss: 0.5047 - accuracy: 0.8111 - val_loss: 0.1857 - val_accuracy: 0.9000\n",
            "Epoch 70/100\n",
            "90/90 [==============================] - 0s 836us/step - loss: 0.5785 - accuracy: 0.7889 - val_loss: 0.1851 - val_accuracy: 0.9000\n",
            "Epoch 71/100\n",
            "90/90 [==============================] - 0s 856us/step - loss: 0.5451 - accuracy: 0.7889 - val_loss: 0.1237 - val_accuracy: 0.9000\n",
            "Epoch 72/100\n",
            "90/90 [==============================] - 0s 851us/step - loss: 0.4972 - accuracy: 0.7889 - val_loss: 0.0821 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "90/90 [==============================] - 0s 929us/step - loss: 0.5259 - accuracy: 0.7778 - val_loss: 0.0712 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "90/90 [==============================] - 0s 895us/step - loss: 0.4659 - accuracy: 0.8000 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "90/90 [==============================] - 0s 872us/step - loss: 0.4675 - accuracy: 0.8444 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00075: saving model to ./model_75.hdf5\n",
            "Epoch 76/100\n",
            "90/90 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.8444 - val_loss: 0.0435 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "90/90 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.8444 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "90/90 [==============================] - 0s 874us/step - loss: 0.5985 - accuracy: 0.8111 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "90/90 [==============================] - 0s 892us/step - loss: 0.5107 - accuracy: 0.8444 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "90/90 [==============================] - 0s 873us/step - loss: 0.5604 - accuracy: 0.7889 - val_loss: 0.1083 - val_accuracy: 0.9000\n",
            "Epoch 81/100\n",
            "90/90 [==============================] - 0s 859us/step - loss: 0.5619 - accuracy: 0.8222 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "90/90 [==============================] - 0s 873us/step - loss: 0.2863 - accuracy: 0.8778 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "90/90 [==============================] - 0s 872us/step - loss: 0.3368 - accuracy: 0.8667 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "90/90 [==============================] - 0s 861us/step - loss: 0.2958 - accuracy: 0.8667 - val_loss: 0.1037 - val_accuracy: 0.9000\n",
            "Epoch 85/100\n",
            "90/90 [==============================] - 0s 897us/step - loss: 0.4705 - accuracy: 0.8667 - val_loss: 0.1659 - val_accuracy: 0.9000\n",
            "Epoch 86/100\n",
            "90/90 [==============================] - 0s 840us/step - loss: 0.3917 - accuracy: 0.8444 - val_loss: 0.1637 - val_accuracy: 0.9000\n",
            "Epoch 87/100\n",
            "90/90 [==============================] - 0s 862us/step - loss: 0.3934 - accuracy: 0.8444 - val_loss: 0.1102 - val_accuracy: 0.9000\n",
            "Epoch 88/100\n",
            "90/90 [==============================] - 0s 863us/step - loss: 0.3655 - accuracy: 0.8444 - val_loss: 0.0956 - val_accuracy: 0.9000\n",
            "Epoch 89/100\n",
            "90/90 [==============================] - 0s 870us/step - loss: 0.4587 - accuracy: 0.8444 - val_loss: 0.1244 - val_accuracy: 0.9000\n",
            "Epoch 90/100\n",
            "90/90 [==============================] - 0s 857us/step - loss: 0.3775 - accuracy: 0.8778 - val_loss: 0.1907 - val_accuracy: 0.9000\n",
            "Epoch 91/100\n",
            "90/90 [==============================] - 0s 849us/step - loss: 0.5323 - accuracy: 0.8556 - val_loss: 0.2268 - val_accuracy: 0.9000\n",
            "Epoch 92/100\n",
            "90/90 [==============================] - 0s 900us/step - loss: 0.3572 - accuracy: 0.9000 - val_loss: 0.2232 - val_accuracy: 0.9000\n",
            "Epoch 93/100\n",
            "90/90 [==============================] - 0s 886us/step - loss: 0.3320 - accuracy: 0.8889 - val_loss: 0.1553 - val_accuracy: 0.9000\n",
            "Epoch 94/100\n",
            "90/90 [==============================] - 0s 861us/step - loss: 0.3498 - accuracy: 0.8889 - val_loss: 0.1210 - val_accuracy: 0.9000\n",
            "Epoch 95/100\n",
            "90/90 [==============================] - 0s 844us/step - loss: 0.3634 - accuracy: 0.8556 - val_loss: 0.1113 - val_accuracy: 0.9000\n",
            "Epoch 96/100\n",
            "90/90 [==============================] - 0s 891us/step - loss: 0.3063 - accuracy: 0.8667 - val_loss: 0.1043 - val_accuracy: 0.9000\n",
            "Epoch 97/100\n",
            "90/90 [==============================] - 0s 941us/step - loss: 0.4356 - accuracy: 0.8556 - val_loss: 0.1233 - val_accuracy: 0.9000\n",
            "Epoch 98/100\n",
            "90/90 [==============================] - 0s 863us/step - loss: 0.3997 - accuracy: 0.8222 - val_loss: 0.1340 - val_accuracy: 0.9000\n",
            "Epoch 99/100\n",
            "90/90 [==============================] - 0s 840us/step - loss: 0.3122 - accuracy: 0.8444 - val_loss: 0.1685 - val_accuracy: 0.9000\n",
            "Epoch 100/100\n",
            "90/90 [==============================] - 0s 862us/step - loss: 0.3687 - accuracy: 0.8667 - val_loss: 0.2403 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00100: saving model to ./model_100.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbzt1qHGG7ug",
        "colab_type": "text"
      },
      "source": [
        "The above command trains a model using the images we prepared for 50 epochs using a learning rate of 0.0001 and a categorical cross-entropy loss function. The `checkpoint_freq = 25` parameter also ensures that every 25 epochs, a snapshot of the model is saved. These models are named as `model_x.hdf5` where x refers to the epoch at which the model was saved. The `input_shape` parameter specifies the shape of the input images. Setting this to `SDSS` automatically sets the value to `(167,167,1)`\n",
        "\n",
        "For an explanation of the different input parameters of `gamornet_train_keras`, pelase have a look at the [API documentation](https://gamornet.readthedocs.io/en/latest/api_docs.html).\n",
        "\n",
        "In the output above, the `accuracy` and `loss` refer to the metrics calculated on the training set at the end of each epoch while `val_loss` and `val_accuracy` refer to the metrics calculated on the validation data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qhQgRdXJtwE",
        "colab_type": "text"
      },
      "source": [
        "Thus, you have trained your first GaMorNet model!! You can have a look at the model's structure using the command below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fs124brJpVI",
        "colab_type": "code",
        "outputId": "f8cf6c33-7a46-4ecf-b732-4beafc1af66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 42, 42, 96)        11712     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 96)        0         \n",
            "_________________________________________________________________\n",
            "local_response_normalization (None, 21, 21, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 21, 21, 256)       614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 256)       0         \n",
            "_________________________________________________________________\n",
            "local_response_normalization (None, 11, 11, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 384)       885120    \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 11, 11, 256)       884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "local_response_normalization (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              37752832  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 12291     \n",
            "=================================================================\n",
            "Total params: 58,270,403\n",
            "Trainable params: 58,270,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkVOkDibLMmD",
        "colab_type": "text"
      },
      "source": [
        "**Important:**\n",
        "The above process also generates a `metrics.csv` file, which contains the loss and accuracy calculated on the validation as well as the training data. \n",
        "\n",
        "We highly recommend using the data in this file to check how the loss and accuracies vary with training. This is extremely helpful in judging whether the model was trained properly and sufficiently. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DtKTEFpyHpHY"
      },
      "source": [
        "# Training GaMorNet using TFLearn\n",
        "\n",
        "Now, we will be using the images and the labels generated above to train GaMorNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c0a1da45-f37c-47c1-e732-277934e7b6f1",
        "id": "OUP-k-NtHpHa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "from gamornet.tflearn_module import gamornet_train_tflearn\n",
        "\n",
        "model = gamornet_train_tflearn(training_imgs,training_labels,valdiation_imgs,\n",
        "                             validation_labels,input_shape='SDSS', epochs=50, \n",
        "                             max_checkpoints=2, batch_size=64, lr=0.0001, \n",
        "                             loss='categorical_crossentropy',clear_session=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.51189\u001b[0m\u001b[0m | time: 0.027s\n",
            "| Momentum | epoch: 071 | loss: 0.51189 - acc: 0.7830 -- iter: 64/90\n",
            "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.51534\u001b[0m\u001b[0m | time: 1.074s\n",
            "| Momentum | epoch: 071 | loss: 0.51534 - acc: 0.7816 | val_loss: 0.18553 - val_acc: 1.0000 -- iter: 90/90\n",
            "--\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a72333839881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                              \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SDSS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              \u001b[0mmax_checkpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                              loss='categorical_crossentropy',clear_session=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gamornet/tflearn_module.py\u001b[0m in \u001b[0;36mgamornet_train_tflearn\u001b[0;34m(training_imgs, training_labels, validation_imgs, validation_labels, input_shape, files_save_path, epochs, max_checkpoints, batch_size, lr, momentum, decay, nesterov, loss, load_model, model_load_path, save_model, show_metric, clear_session)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     model.fit(training_imgs, training_labels, n_epoch=epochs, validation_set=(validation_imgs, validation_labels),\n\u001b[0;32m--> 385\u001b[0;31m               shuffle=True, show_metric=show_metric, batch_size=batch_size, snapshot_step=None, snapshot_epoch=save_model)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[1;32m    214\u001b[0m                          \u001b[0mexcl_trainops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexcl_trainops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                          \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                          callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# Epoch end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                     \u001b[0mcaller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tflearn/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, training_state)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tflearn/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, training_state)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshot_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tflearn/callbacks.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, training_step)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshot_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshot_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, model_file, global_step)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_saver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[1;32m   1174\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1175\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u9StaWVvHpHe"
      },
      "source": [
        "The above command trains a model using the images we prepared for 50 epochs using a learning rate of 0.0001 and a categorical cross-entropy loss function. The `max_checkpoints = 2` parameter ensures that the latest 2 snapshots of the epochs will always be saved during training. Three files are saved for each snapshot and the naming format of the checkpoints is `check-x.data`,`check-x.index`,`check-x.meta` where x refers to the step number at which the model was saved. The `input_shape` parameter specifies the shape of the input images. Setting this to `SDSS` automatically sets the value to `(167,167,1)`. \n",
        "\n",
        "In the output above, the `acc` and `loss` refer to the accuracy and loss calculated on the training set at the end of each epoch while `val_loss` and `val_acc` refer to the metrics calculated on the validation data. \n",
        "\n",
        "The `clear_session = True` parameter value instructs GaMorNet to clear the TensorFlow graphs created earlier. We highly recommend `clear_session` to `True` in notebooks while using the `tflearn_module` as otherwise it might fail. \n",
        "\n",
        "For an explanation of the different input parameters of `gamornet_train_tflearn`, pelase have a look at the [API documentation](https://gamornet.readthedocs.io/en/latest/api_docs.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rKXigHG6J8Fj"
      },
      "source": [
        "Thus, you have trained your first GaMorNet model!! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSoVi9LRMhUv",
        "colab_type": "text"
      },
      "source": [
        "**Tip:** Unlike with the keras module, the tflearn module doesn't automatically save the metrics. Instead you have to redirect the Python output generated to a file in order to keep track of the metrics. \n",
        "\n",
        "When running some python script this can be done simply using `python script.py > out.txt`. This will save all the screen output in `out.txt`.\n",
        "\n",
        "Thereafter the following snippet of Python Code can easily search for the relevant metrics in the screen output file. \n",
        "\n",
        "```python\n",
        "###################################\n",
        "# accParser.py\n",
        "#\n",
        "# Takes tflearn screen output and extracts loss, acc and val_acc every epoch for visualization\n",
        "####################################\n",
        "import sys\n",
        "\n",
        "if (len(sys.argv) != 2):\n",
        "        print \"Exiting Program....\\nUsage: python accParser.py /path/to/screen/output\"\n",
        "\n",
        "\n",
        "dataPath = sys.argv[1] #the first argument is the path to the screen grab of the TF Learn run\n",
        "\n",
        "dataFile = open(dataPath, 'r')\n",
        "outFile = open(dataPath[:-6] + 'out.txt', 'w')\n",
        "\n",
        "outFile.write(\"epoch loss acc val_acc\\n\")\n",
        "resultLines = dataFile.readlines()\n",
        "\n",
        "for line in resultLines:\n",
        "        if 'val_acc' in line:\n",
        "                words = line.split()\n",
        "\n",
        "                #validation step\n",
        "                if words[-2:-1] != ['iter:']:\n",
        "                        print \"Something doesn't look right. Skipping an occurene of val_acc\"\n",
        "                        continue\n",
        "\n",
        "                outFile.write(words[words.index(\"epoch:\")+1] + \" \")\n",
        "                outFile.write(words[words.index(\"loss:\")+1] + \" \")\n",
        "                outFile.write(words[words.index(\"acc:\")+1] + \" \")\n",
        "                outFile.write(words[words.index(\"val_acc:\")+1] + \"\\n\")\n",
        "\n",
        "dataFile.close()\n",
        "outFile.close()\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CI4QJAROoGo",
        "colab_type": "text"
      },
      "source": [
        "**Important:** We highly recommend checking how the loss and accuracies vary with training. This is extremely helpful in judging whether the model was trained properly and sufficiently. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Trd52HQV7xU",
        "colab_type": "text"
      },
      "source": [
        "# Summary & Takeaways\n",
        "\n",
        "* `gamornet_train_keras` and `gamornet_train_tflearn` are the two functions that can be used to train GaMorNet models. \n",
        "\n",
        "* For understanding the differences between the Keras and TFLearn modules, please refer to the [PDR Handbook](https://gamornet.readthedocs.io/en/latest/usage_guide.html). \n",
        "\n",
        "* The [PDR Handbook](https://gamornet.readthedocs.io/en/latest/usage_guide.html) also contains advice about which situations warrant the training of models from scratch and in which cases you can use the models which we have released. "
      ]
    }
  ]
}