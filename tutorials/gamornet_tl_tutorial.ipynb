{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "gamornet_basics_tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aritraghsh09/GaMorNet/blob/master/tutorials/gamornet_tl_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNq4HgykhnJK",
        "colab_type": "text"
      },
      "source": [
        "# Google Colab Stuff\n",
        "\n",
        "Although this tutorial can be run on any machine which has GaMorNet installed, it's pretty handy to run this on Google Colab as you can easily use Colab's GPUs for this tutorial.\n",
        "\n",
        "Note that with the free version of Colab, you will only have access to a limited amount of memory available. Thus, the number of images we use here for training/testing very small just for the purpose of demonstration. In reality, GaMorNet can hands hundreds of thousands of images. \n",
        "\n",
        "This first section is meant to be run only when following this tutorial in Google Colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2wSGVu4ihqa",
        "colab_type": "text"
      },
      "source": [
        "### Make things Fast!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWvqtYGaijke",
        "colab_type": "text"
      },
      "source": [
        "Before we dive in, let's make sure we're using a GPU for this tutorial.  \n",
        "\n",
        "To do this, select \"Runtime\" -> \"Change runtime type\" -> \"Hardware accelerator\" -> \"GPU\".\n",
        "\n",
        "The following snippet will verify that we have access to a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbBNuljhhnyf",
        "colab_type": "code",
        "outputId": "9a203cac-dc6a-4df3-e756-0d8289f000c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "# Suppressing TF warnings and info for a cleaner environ\n",
        "# Set this to 0,1 for info and warnings respectively.\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        " \n",
        "# Magic telling Colab we want TF version ~=1.0\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "#Checking access to GPU\n",
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
        "  print('WARNING: GPU device not found.')\n",
        "else:\n",
        "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "SUCCESS: Found GPU: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en4lZVmont-b",
        "colab_type": "text"
      },
      "source": [
        "### Install GaMorNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywr-x3csgQ5f",
        "colab_type": "code",
        "outputId": "aeaf8db2-eed9-4284-b30a-85dc734fcc4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install -q --upgrade gamornet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 411.0MB 43kB/s \n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYsnfr7tj3D-",
        "colab_type": "code",
        "outputId": "fa6ef2a0-6992-40bb-9b2d-849131287cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "##Checking which version of Tensorflow is being used and whether the installation worked.\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from gamornet.keras_module import gamornet_train_keras, gamornet_tl_keras, gamornet_predict_keras\n",
        "from gamornet.tflearn_module import gamornet_train_tflearn, gamornet_tl_tflearn, gamornet_predict_tflearn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isCigPq4TiWi",
        "colab_type": "text"
      },
      "source": [
        "# Reference\n",
        "\n",
        "All mentions of \"the paper\" in this tutorial, refer to [Ghosh et. al. (2020)](https://iopscience.iop.org/article/10.3847/1538-4357/ab8a47)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUDD3Qke7Ws_",
        "colab_type": "text"
      },
      "source": [
        "# Installing Libraries Needed for this Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBSCZfMM7WJV",
        "colab_type": "code",
        "outputId": "7a53d767-8fd2-4681-9ee5-321b9599ba67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!pip install matplotlib"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZdvFR_IgTmn",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning with GaMorNet\n",
        "\n",
        "GaMorNet models that have been trained before can easily be refined using new data. This is the basic idea behind transfer learning.  \n",
        "\n",
        "In this demonstration, we will start with simulation-trained SDSS model that we have released in the paper. Thereafter, we will perform transfer learning on this mode. For this, we will use 90 real SDSS galaxies for the purposes of training and 10 real SDSS galaxies for validation. All these images are in the g-band and are part of the SDSS data-set used in the paper. \n",
        "\n",
        "The simulations that the base model was trained on contain disk + bulge components. As described in the paper, we also convolved these simulations with a representative PSF and added representative noise. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwzpM9YMUPqn",
        "colab_type": "text"
      },
      "source": [
        "# Downloading the Data\n",
        "\n",
        "First, let's download the images that we are going to use to transfer learn. We will download these into the local filesystem from Yale Astronomy's FTP service, where these are hosted.\n",
        "\n",
        "We are going to download all the 100 images (90+10) as a single archive and then export it to a single folder called `training_imgs`. The iamges are in the FITS format and the names of the images are their SDSS Object IDs.\n",
        "\n",
        "We are also going to download the `gal_para.txt` file containing the ground-truth parameters for the above galaxies from [Simard et. al. (2011)](https://iopscience.iop.org/article/10.1088/0067-0049/196/1/11). Using thes bulge-to-total light ratio of each galaxy, we will determine the labels to be used during the transfer learning process. \n",
        "\n",
        "\n",
        "*Tip: The `%%bash` command lets Colab know that all the commands in this shell needs to be passed the local unix virtual environment.*\n",
        "\n",
        "*Tip: To view the files in use on Colab, click the folder icon on the left sidebar.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TThUIR8Y4lc",
        "colab_type": "code",
        "outputId": "1de555ce-dfe4-4381-dd4d-0311c6e87bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash\n",
        "#get zip and txt file from server\n",
        "wget ftp://ftp.astro.yale.edu/pub/aghosh/gamornet_tutorial_files/tl_images/tl_images.tar.gz\n",
        "wget ftp://ftp.astro.yale.edu/pub/aghosh/gamornet_tutorial_files/tl_images/gal_para.txt\n",
        "\n",
        "#Unzip the Archive\n",
        "tar -xvf tl_images.tar.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./tl_images/587722953304440846-g.fits\n",
            "./tl_images/587722981750014081-g.fits\n",
            "./tl_images/587722982298026184-g.fits\n",
            "./tl_images/587722982812155970-g.fits\n",
            "./tl_images/587722982831161384-g.fits\n",
            "./tl_images/587722983365279858-g.fits\n",
            "./tl_images/587722983366721714-g.fits\n",
            "./tl_images/587722983369408606-g.fits\n",
            "./tl_images/587722983369408874-g.fits\n",
            "./tl_images/587722983897890856-g.fits\n",
            "./tl_images/587722983902806142-g.fits\n",
            "./tl_images/587722983908049268-g.fits\n",
            "./tl_images/587722983910932754-g.fits\n",
            "./tl_images/587722983912767673-g.fits\n",
            "./tl_images/587722984429322343-g.fits\n",
            "./tl_images/587722984438038680-g.fits\n",
            "./tl_images/587722984439545906-g.fits\n",
            "./tl_images/587722984440659987-g.fits\n",
            "./tl_images/587722984440791232-g.fits\n",
            "./tl_images/587722984443216081-g.fits\n",
            "./tl_images/587724197211144263-g.fits\n",
            "./tl_images/587724197741854834-g.fits\n",
            "./tl_images/587724197743362189-g.fits\n",
            "./tl_images/587724197745918122-g.fits\n",
            "./tl_images/587724197746704505-g.fits\n",
            "./tl_images/587724197747032159-g.fits\n",
            "./tl_images/587724198277415036-g.fits\n",
            "./tl_images/587724198278725806-g.fits\n",
            "./tl_images/587724198279053466-g.fits\n",
            "./tl_images/587724198279446731-g.fits\n",
            "./tl_images/587724198282461323-g.fits\n",
            "./tl_images/587724198282920103-g.fits\n",
            "./tl_images/587724198285279370-g.fits\n",
            "./tl_images/587724198816645382-g.fits\n",
            "./tl_images/587724198816841872-g.fits\n",
            "./tl_images/587724198822412473-g.fits\n",
            "./tl_images/587724199349846160-g.fits\n",
            "./tl_images/587724199352729859-g.fits\n",
            "./tl_images/587724199887044764-g.fits\n",
            "./tl_images/587724199889666153-g.fits\n",
            "./tl_images/587724199889797351-g.fits\n",
            "./tl_images/587724199894057120-g.fits\n",
            "./tl_images/587724231565574263-g.fits\n",
            "./tl_images/587724231567802508-g.fits\n",
            "./tl_images/587724232100675610-g.fits\n",
            "./tl_images/587724232102641838-g.fits\n",
            "./tl_images/587724232110375026-g.fits\n",
            "./tl_images/587724232638201976-g.fits\n",
            "./tl_images/587724232639512732-g.fits\n",
            "./tl_images/587724232640299135-g.fits\n",
            "./tl_images/587724232640823418-g.fits\n",
            "./tl_images/587724232641937529-g.fits\n",
            "./tl_images/587724232645017746-g.fits\n",
            "./tl_images/587724232645083176-g.fits\n",
            "./tl_images/587724233177759864-g.fits\n",
            "./tl_images/587724233178480762-g.fits\n",
            "./tl_images/587724233179791424-g.fits\n",
            "./tl_images/587724233712599147-g.fits\n",
            "./tl_images/587724233715023967-g.fits\n",
            "./tl_images/587724233715024035-g.fits\n",
            "./tl_images/587724233715089476-g.fits\n",
            "./tl_images/587724233717776443-g.fits\n",
            "./tl_images/587724233720004817-g.fits\n",
            "./tl_images/587724234249732319-g.fits\n",
            "./tl_images/587724234251436159-g.fits\n",
            "./tl_images/587724234251829389-g.fits\n",
            "./tl_images/587724240154853493-g.fits\n",
            "./tl_images/587724240687267890-g.fits\n",
            "./tl_images/587724240690282547-g.fits\n",
            "./tl_images/587724240694673502-g.fits\n",
            "./tl_images/587724241226170380-g.fits\n",
            "./tl_images/587724241228726404-g.fits\n",
            "./tl_images/587724241232462000-g.fits\n",
            "./tl_images/587724242300895371-g.fits\n",
            "./tl_images/587724242308038811-g.fits\n",
            "./tl_images/587724648179433616-g.fits\n",
            "./tl_images/587724648185135182-g.fits\n",
            "./tl_images/587724648188674155-g.fits\n",
            "./tl_images/587724648191098979-g.fits\n",
            "./tl_images/587724648723710103-g.fits\n",
            "./tl_images/587724648726331503-g.fits\n",
            "./tl_images/587724649255469071-g.fits\n",
            "./tl_images/587724649790111843-g.fits\n",
            "./tl_images/587724650327113903-g.fits\n",
            "./tl_images/587724650329145594-g.fits\n",
            "./tl_images/587724650329276573-g.fits\n",
            "./tl_images/587724650864050209-g.fits\n",
            "./tl_images/587724650864181415-g.fits\n",
            "./tl_images/587724650864574562-g.fits\n",
            "./tl_images/587724650864574666-g.fits\n",
            "./tl_images/587725039016280152-g.fits\n",
            "./tl_images/587725039019491473-g.fits\n",
            "./tl_images/587725039021916298-g.fits\n",
            "./tl_images/587725039026307236-g.fits\n",
            "./tl_images/587725039555248209-g.fits\n",
            "./tl_images/587725039560491033-g.fits\n",
            "./tl_images/587725039562850481-g.fits\n",
            "./tl_images/587725040093036670-g.fits\n",
            "./tl_images/587725040093298792-g.fits\n",
            "./tl_images/587725040626106522-g.fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--2020-06-12 01:21:35--  ftp://ftp.astro.yale.edu/pub/aghosh/gamornet_tutorial_files/tl_images/tl_images.tar.gz\n",
            "           => ‘tl_images.tar.gz’\n",
            "Resolving ftp.astro.yale.edu (ftp.astro.yale.edu)... 128.36.139.12\n",
            "Connecting to ftp.astro.yale.edu (ftp.astro.yale.edu)|128.36.139.12|:21... connected.\n",
            "Logging in as anonymous ... Logged in!\n",
            "==> SYST ... done.    ==> PWD ... done.\n",
            "==> TYPE I ... done.  ==> CWD (1) /pub/aghosh/gamornet_tutorial_files/tl_images ... done.\n",
            "==> SIZE tl_images.tar.gz ... 3709327\n",
            "==> PASV ... done.    ==> RETR tl_images.tar.gz ... done.\n",
            "Length: 3709327 (3.5M) (unauthoritative)\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  1%  585K 6s\n",
            "    50K .......... .......... .......... .......... ..........  2% 25.6M 3s\n",
            "   100K .......... .......... .......... .......... ..........  4% 1.65M 3s\n",
            "   150K .......... .......... .......... .......... ..........  5%  298M 2s\n",
            "   200K .......... .......... .......... .......... ..........  6% 2.08M 2s\n",
            "   250K .......... .......... .......... .......... ..........  8%  328M 2s\n",
            "   300K .......... .......... .......... .......... ..........  9% 6.04M 1s\n",
            "   350K .......... .......... .......... .......... .......... 11% 2.12M 1s\n",
            "   400K .......... .......... .......... .......... .......... 12%  331M 1s\n",
            "   450K .......... .......... .......... .......... .......... 13% 5.18M 1s\n",
            "   500K .......... .......... .......... .......... .......... 15%  300M 1s\n",
            "   550K .......... .......... .......... .......... .......... 16% 2.22M 1s\n",
            "   600K .......... .......... .......... .......... .......... 17%  344M 1s\n",
            "   650K .......... .......... .......... .......... .......... 19% 4.84M 1s\n",
            "   700K .......... .......... .......... .......... .......... 20% 2.32M 1s\n",
            "   750K .......... .......... .......... .......... .......... 22%  292M 1s\n",
            "   800K .......... .......... .......... .......... .......... 23% 4.29M 1s\n",
            "   850K .......... .......... .......... .......... .......... 24%  324M 1s\n",
            "   900K .......... .......... .......... .......... .......... 26% 4.84M 1s\n",
            "   950K .......... .......... .......... .......... .......... 27%  320M 1s\n",
            "  1000K .......... .......... .......... .......... .......... 28% 5.34M 1s\n",
            "  1050K .......... .......... .......... .......... .......... 30% 47.3M 1s\n",
            "  1100K .......... .......... .......... .......... .......... 31% 5.30M 1s\n",
            "  1150K .......... .......... .......... .......... .......... 33% 69.3M 1s\n",
            "  1200K .......... .......... .......... .......... .......... 34% 5.72M 1s\n",
            "  1250K .......... .......... .......... .......... .......... 35% 42.9M 1s\n",
            "  1300K .......... .......... .......... .......... .......... 37% 5.51M 0s\n",
            "  1350K .......... .......... .......... .......... .......... 38% 63.1M 0s\n",
            "  1400K .......... .......... .......... .......... .......... 40% 62.5M 0s\n",
            "  1450K .......... .......... .......... .......... .......... 41% 5.77M 0s\n",
            "  1500K .......... .......... .......... .......... .......... 42% 54.6M 0s\n",
            "  1550K .......... .......... .......... .......... .......... 44% 5.43M 0s\n",
            "  1600K .......... .......... .......... .......... .......... 45% 64.6M 0s\n",
            "  1650K .......... .......... .......... .......... .......... 46% 5.84M 0s\n",
            "  1700K .......... .......... .......... .......... .......... 48% 53.6M 0s\n",
            "  1750K .......... .......... .......... .......... .......... 49% 5.36M 0s\n",
            "  1800K .......... .......... .......... .......... .......... 51% 93.6M 0s\n",
            "  1850K .......... .......... .......... .......... .......... 52% 59.4M 0s\n",
            "  1900K .......... .......... .......... .......... .......... 53% 5.82M 0s\n",
            "  1950K .......... .......... .......... .......... .......... 55% 64.5M 0s\n",
            "  2000K .......... .......... .......... .......... .......... 56% 5.36M 0s\n",
            "  2050K .......... .......... .......... .......... .......... 57%  116M 0s\n",
            "  2100K .......... .......... .......... .......... .......... 59% 62.4M 0s\n",
            "  2150K .......... .......... .......... .......... .......... 60% 5.86M 0s\n",
            "  2200K .......... .......... .......... .......... .......... 62% 72.9M 0s\n",
            "  2250K .......... .......... .......... .......... .......... 63% 5.32M 0s\n",
            "  2300K .......... .......... .......... .......... .......... 64% 88.4M 0s\n",
            "  2350K .......... .......... .......... .......... .......... 66% 72.9M 0s\n",
            "  2400K .......... .......... .......... .......... .......... 67% 5.90M 0s\n",
            "  2450K .......... .......... .......... .......... .......... 69% 79.0M 0s\n",
            "  2500K .......... .......... .......... .......... .......... 70% 69.1M 0s\n",
            "  2550K .......... .......... .......... .......... .......... 71% 5.46M 0s\n",
            "  2600K .......... .......... .......... .......... .......... 73% 72.0M 0s\n",
            "  2650K .......... .......... .......... .......... .......... 74% 78.2M 0s\n",
            "  2700K .......... .......... .......... .......... .......... 75% 5.85M 0s\n",
            "  2750K .......... .......... .......... .......... .......... 77% 80.2M 0s\n",
            "  2800K .......... .......... .......... .......... .......... 78% 5.44M 0s\n",
            "  2850K .......... .......... .......... .......... .......... 80%  104M 0s\n",
            "  2900K .......... .......... .......... .......... .......... 81% 81.2M 0s\n",
            "  2950K .......... .......... .......... .......... .......... 82% 92.1M 0s\n",
            "  3000K .......... .......... .......... .......... .......... 84% 5.86M 0s\n",
            "  3050K .......... .......... .......... .......... .......... 85% 71.6M 0s\n",
            "  3100K .......... .......... .......... .......... .......... 86% 5.35M 0s\n",
            "  3150K .......... .......... .......... .......... .......... 88%  202M 0s\n",
            "  3200K .......... .......... .......... .......... .......... 89% 76.4M 0s\n",
            "  3250K .......... .......... .......... .......... .......... 91%  101M 0s\n",
            "  3300K .......... .......... .......... .......... .......... 92% 5.85M 0s\n",
            "  3350K .......... .......... .......... .......... .......... 93% 79.4M 0s\n",
            "  3400K .......... .......... .......... .......... .......... 95% 5.31M 0s\n",
            "  3450K .......... .......... .......... .......... .......... 96%  107M 0s\n",
            "  3500K .......... .......... .......... .......... .......... 98%  126M 0s\n",
            "  3550K .......... .......... .......... .......... .......... 99%  118M 0s\n",
            "  3600K .......... .......... ..                              100% 85.6M=0.5s\n",
            "\n",
            "2020-06-12 01:21:35 (7.80 MB/s) - ‘tl_images.tar.gz’ saved [3709327]\n",
            "\n",
            "--2020-06-12 01:21:35--  ftp://ftp.astro.yale.edu/pub/aghosh/gamornet_tutorial_files/tl_images/gal_para.txt\n",
            "           => ‘gal_para.txt’\n",
            "Resolving ftp.astro.yale.edu (ftp.astro.yale.edu)... 128.36.139.12\n",
            "Connecting to ftp.astro.yale.edu (ftp.astro.yale.edu)|128.36.139.12|:21... connected.\n",
            "Logging in as anonymous ... Logged in!\n",
            "==> SYST ... done.    ==> PWD ... done.\n",
            "==> TYPE I ... done.  ==> CWD (1) /pub/aghosh/gamornet_tutorial_files/tl_images ... done.\n",
            "==> SIZE gal_para.txt ... 7266\n",
            "==> PASV ... done.    ==> RETR gal_para.txt ... done.\n",
            "Length: 7266 (7.1K) (unauthoritative)\n",
            "\n",
            "     0K .......                                               100% 5.31M=0.001s\n",
            "\n",
            "2020-06-12 01:21:36 (5.31 MB/s) - ‘gal_para.txt’ saved [7266]\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAwLO4hk-C3Q",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the Data\n",
        "\n",
        "In this section, we will generate the training and validation image arrays as well as the corresponding labels to be used during the transfer learning process.\n",
        "\n",
        "\n",
        "First, lets read in the `.txt` file, which will help us to figure out the label for each galaxy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex46Lm2c_3I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pylab as plt\n",
        "\n",
        "#Let's read in the sim_para.txt file \n",
        "gal_para = plt.genfromtxt(\"./gal_para.txt\",names=True,dtype=None,encoding=None)\n",
        " \n",
        "#The file has a column called \"bt_g\" which is the bulge to total light ration\n",
        "#for each galaxy as measured by Simard et. al. 2011. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pDautJ1CWTy",
        "colab_type": "text"
      },
      "source": [
        "Next, let's define two convenience functions, which will assist us in creating the image and label arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWcg5PBi-RSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convenience Function to get and return images as numpy arrays\n",
        "\n",
        "def image_handler(i):\n",
        "  return np.reshape(fits.getdata(\"./tl_images/\"+gal_para[\"file_name\"][i],\n",
        "                                 memmap=False),newshape=(167,167,1)) \n",
        "  #We use the reshape command just to add the extra 3rd dimension. The image is \n",
        "  #originally 167*167. So, in essence no re-sizing is taking place in the X or Y\n",
        "  #directions.\n",
        "\n",
        "\n",
        "# Convenience Function to get and return the training labels of each galaxy\n",
        "# in the one-hot encoding format. i.e. disk-dominated galaxies will be represented\n",
        "# by the array [1,0,0], bulge-dominated by [0,0,1] and indeterminate by [0,1,0]\n",
        "\n",
        "def label_handler(i):\n",
        "  \n",
        "  target_vect = [0]*3\n",
        "\n",
        "  if gal_para[\"bt_g\"][i] < 0.45: #disk-dminated\n",
        "    target_vect[0] = 1\n",
        "\n",
        "  elif 0.45 <= gal_para[\"bt_g\"][i] <= 0.55: #indeterminate\n",
        "    target_vect[1] = 1\n",
        "\n",
        "  else: #bulge-dominated\n",
        "    target_vect[2] = 1\n",
        "\n",
        "  return target_vect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQesQrpK-Pz2",
        "colab_type": "text"
      },
      "source": [
        "Now, we are going to use the first 90 images to create the training set and the last 10 to create the validation set. We are multi-threading the process below -- although this is an absolute overkill for 100 images, it's very handy while dealing with large numbers of images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_SCF8wWDiSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from multiprocessing import Pool\n",
        "import numpy as np\n",
        "from astropy.io import fits\n",
        "\n",
        "NUM_THREADS = 2\n",
        "\n",
        "pl = Pool(NUM_THREADS)\n",
        "training_imgs = np.array(pl.map(image_handler,range(0,90)))\n",
        "training_labels = np.array(pl.map(label_handler,range(0,90)))\n",
        "\n",
        "valdiation_imgs = np.array(pl.map(image_handler,range(90,100)))\n",
        "validation_labels = np.array(pl.map(label_handler,range(90,100)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw-l4YKMbLdK",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning on GaMorNet using Keras\n",
        "\n",
        "Now, we will be using the images and the labels generated above to transfer learn on GaMorNet. \n",
        "\n",
        "The main goal of transfer learning is to refine a previously trained model. Thus, as a starting point, we will be using the model trained on SDSS simulations in the paper. \n",
        "\n",
        "One of the other primary decisions to take during transfer learning is \n",
        "\n",
        "* whether you want to train all the layers or whether you want to freeze some of the them. The `trainable_bools` parameter controls this. \n",
        "\n",
        "* whether you want to initialize all the models from the previously trained model or whether you want to initialize some of the layers from scratch. The `load_layers_bools` parameter controls this. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBTLm74QbMnG",
        "colab_type": "code",
        "outputId": "bf4f85e3-1028-4524-fda5-06ed4e1f6a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from gamornet.keras_module import gamornet_tl_keras\n",
        "\n",
        "model = gamornet_tl_keras(training_imgs,training_labels,valdiation_imgs,validation_labels, \n",
        "                          input_shape='SDSS', load_layers_bools='load_bools_SDSS', \n",
        "                          trainable_bools='train_bools_SDSS', \n",
        "                          model_load_path='SDSS_sim', epochs=20, checkpoint_freq=10, \n",
        "                          batch_size=64, lr=0.00001, loss='categorical_crossentropy')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Fetching SDSS Sim Trained Weigths.....\n",
            "Loading Layer0 from previous model.\n",
            "Loading Layer3 from previous model.\n",
            "Loading Layer6 from previous model.\n",
            "Loading Layer7 from previous model.\n",
            "Loading Layer8 from previous model.\n",
            "Initializing Layer12 from scratch\n",
            "Initializing Layer14 from scratch\n",
            "Initializing Layer16 from scratch\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Train on 90 samples, validate on 10 samples\n",
            "Epoch 1/20\n",
            "90/90 [==============================] - 7s 83ms/step - loss: 1.2314 - accuracy: 0.3222 - val_loss: 1.1959 - val_accuracy: 0.4000\n",
            "Epoch 2/20\n",
            "90/90 [==============================] - 0s 785us/step - loss: 1.1785 - accuracy: 0.3889 - val_loss: 1.1858 - val_accuracy: 0.4000\n",
            "Epoch 3/20\n",
            "90/90 [==============================] - 0s 775us/step - loss: 1.2381 - accuracy: 0.3444 - val_loss: 1.1722 - val_accuracy: 0.4000\n",
            "Epoch 4/20\n",
            "90/90 [==============================] - 0s 747us/step - loss: 1.1184 - accuracy: 0.4556 - val_loss: 1.1562 - val_accuracy: 0.4000\n",
            "Epoch 5/20\n",
            "90/90 [==============================] - 0s 765us/step - loss: 1.1884 - accuracy: 0.4556 - val_loss: 1.1387 - val_accuracy: 0.4000\n",
            "Epoch 6/20\n",
            "90/90 [==============================] - 0s 758us/step - loss: 1.0001 - accuracy: 0.5111 - val_loss: 1.1210 - val_accuracy: 0.4000\n",
            "Epoch 7/20\n",
            "90/90 [==============================] - 0s 756us/step - loss: 1.0192 - accuracy: 0.5222 - val_loss: 1.1034 - val_accuracy: 0.4000\n",
            "Epoch 8/20\n",
            "90/90 [==============================] - 0s 750us/step - loss: 1.0719 - accuracy: 0.5333 - val_loss: 1.0864 - val_accuracy: 0.4000\n",
            "Epoch 9/20\n",
            "90/90 [==============================] - 0s 765us/step - loss: 0.9211 - accuracy: 0.6000 - val_loss: 1.0724 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "90/90 [==============================] - 0s 805us/step - loss: 0.9665 - accuracy: 0.5000 - val_loss: 1.0599 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00010: saving model to ./model_10.hdf5\n",
            "Epoch 11/20\n",
            "90/90 [==============================] - 0s 960us/step - loss: 0.9821 - accuracy: 0.5889 - val_loss: 1.0500 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "90/90 [==============================] - 0s 779us/step - loss: 0.8770 - accuracy: 0.5667 - val_loss: 1.0421 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "90/90 [==============================] - 0s 815us/step - loss: 0.9286 - accuracy: 0.6111 - val_loss: 1.0364 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "90/90 [==============================] - 0s 840us/step - loss: 0.8828 - accuracy: 0.6556 - val_loss: 1.0326 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "90/90 [==============================] - 0s 840us/step - loss: 0.7221 - accuracy: 0.6667 - val_loss: 1.0297 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "90/90 [==============================] - 0s 785us/step - loss: 0.7563 - accuracy: 0.6556 - val_loss: 1.0285 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "90/90 [==============================] - 0s 769us/step - loss: 0.8551 - accuracy: 0.6556 - val_loss: 1.0275 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "90/90 [==============================] - 0s 813us/step - loss: 0.6888 - accuracy: 0.7000 - val_loss: 1.0267 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "90/90 [==============================] - 0s 797us/step - loss: 0.7004 - accuracy: 0.7667 - val_loss: 1.0274 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "90/90 [==============================] - 0s 768us/step - loss: 0.8219 - accuracy: 0.6667 - val_loss: 1.0279 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00020: saving model to ./model_20.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbzt1qHGG7ug",
        "colab_type": "text"
      },
      "source": [
        "In the output above, the `accuracy` and `loss` refer to the metrics calculated on the training set at the end of each epoch while `val_loss` and `val_accuracy` refer to the metrics calculated on the validation data. \n",
        "\n",
        "The above command trains the model using the images we prepared for 20 epochs using a learning rate of 0.00001 and a categorical cross-entropy loss function. The `checkpoint_freq = 10` parameter also ensures that every 10 epochs, a snapshot of the model is saved. These models are named as `model_x.hdf5` where x refers to the epoch at which the model was saved. The `input_shape` parameter specifies the shape of the input images. Setting this to `SDSS` automatically sets the value to `(167,167,1)`.\n",
        "\n",
        "The value of the `load_layers_bools` should be an array of eight bools corresponding to Layer numbers 2, 5, 8, 9, 10, 13, 15, 17 of GaMorNet [(Schematic Diagram)](https://github.com/aritraghsh09/GaMorNet/blob/master/docs/source/images/gamornet_schematic_coloured.png). Setting each array element to `True` means that layer from the previous model. Setting this to `load_bools_SDSS` sets this to the configuration we used in the paper for SDSS data. \n",
        "\n",
        "The value of the `trainable_bools` should be an array of eight bools again corresponding to Layer numbers 2, 5, 8, 9, 10, 13, 15, 17 of GaMorNet [(Schematic Diagram)](https://github.com/aritraghsh09/GaMorNet/blob/master/docs/source/images/gamornet_schematic_coloured.png). Setting each array element to `True` means that wieghts and baises of that layer will be tuned during transfer learning. Otherwise, they would be kept frozen. Setting this to `train_bools_SDSS` sets this to the configuration we used in the paper for SDSS data. \n",
        "\n",
        "For an explanation of the different input parameters of `gamornet_tl_keras`, pelase have a look at the [API documentation](https://gamornet.readthedocs.io/en/latest/api_docs.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qhQgRdXJtwE",
        "colab_type": "text"
      },
      "source": [
        "Thus, you can easily perform transfer learning using GaMorNet!! You can have a look at the model's structure using the command below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fs124brJpVI",
        "colab_type": "code",
        "outputId": "90248854-4233-47b8-d9dd-85ba2affe0a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 42, 42, 96)        11712     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 96)        0         \n",
            "_________________________________________________________________\n",
            "local_response_normalization (None, 21, 21, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 21, 21, 256)       614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 256)       0         \n",
            "_________________________________________________________________\n",
            "local_response_normalization (None, 11, 11, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 384)       885120    \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 11, 11, 256)       884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "local_response_normalization (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              37752832  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 12291     \n",
            "=================================================================\n",
            "Total params: 58,270,403\n",
            "Trainable params: 58,270,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkVOkDibLMmD",
        "colab_type": "text"
      },
      "source": [
        "**Important:**\n",
        "The above process also generates a `metrics.csv` file, which contains the loss and accuracy calculated on the validation as well as the training data. \n",
        "\n",
        "We highly recommend using the data in this file to check how the loss and accuracies vary with training. This is extremely helpful in judging whether the model was trained properly and sufficiently. "
      ]
    }
  ]
}